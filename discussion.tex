Our data access setup is involved and it is desirable to be simplified.
However, we do not have much control over this process because of
our overall approach.
The data are collected by the proprietary Huawei smartwatches,
and synchronized to the proprietary Huawei Health Kit.
This means that we do not have control over when and how the data is
collected or synchronized.
In the future, it would be desirable to have a more open data access setup,
where we control the data collection and synchronization process.

Core ML imposes significant restrictions on \fedkit's on-device training on iOS.
It only supports updating parameters of fully-connected layers and convolutional
layers, therefore limiting the model types that can be trained.
Because the Core ML models are defined in a binary format using ProtoBuf,
and the available loss functions are fixed to be either cross-entropy loss or
mean squared error loss, the Core ML Trainer is not able to support arbitrary
loss functions.
Additionally, we observed a bug in Core ML that causes some models converted
from TensorFlow using CoreMLTools to crash during training when the model uses
cross-entropy loss.
We have reported this issue to Apple.

The proprietary nature of Core ML means that we have little control over its
functionality span and its problems, therefore,
one possible future direction is to replace Core ML with a more open solution.
Microsoft's ONNX Runtime is a promising alternative,
as it is an actively-developed open-source project and now supports training on
both iOS and Android.
However, ONNX Runtime can only leverage the CPU for training on iOS,
missing our goal of having training acceleration.
These trade-offs might be acceptable for some applications,
but ultimately may not be addressable due to Apple's restrictions on access to
programming interfaces for its hardware.

% TODO: Talk about SSL, etc.
Security may be extended by implementing Differential Privacy or
enabling Transport Layer Security.

The inherent heterogeneity of \fedcampus' client devices and data suggests us to
adopt a more tailored scheduling strategies for federated learning.
In this scenario, a small number of clients may lag significantly behind others,
ultimately becoming the bottleneck for the overall training
process~\cite{chen2020asynchronous,zheng2017asynchronous}.
Although we have not observed this issue in our experiments,
likely because of the relatively small number of clients,
we could employ scheduling strategies tailored for heterogeneous devices.
These strategies sample clients each round based on their properties,
and may sample different numbers of clients each
round~\cite[e.g.,][]{zhang2022fedada,karimireddy2019error,reddi2020adaptive,luo2021cost};
they may allow clients to train for different numbers of local epochs based on
their computational capabilities~\cite{li2020federated}; or,
they may adopt an asynchronous
approach~\cite{chilimbi2014project,zhu2022online,huba2022papaya,sun2022fedsea}.
We could adopt some of these existing strategies and compare their performance,
or even develop new strategies that are more tailored to our specific scenario.

Another potential optimization is to minimize the data transfer. Currently,
our system sends all model parameters between the server and the clients each
round,
which may be inefficient considering the limited mobile networks smartphones
operate on.
Federated learning systems often employ strategies to reduce the amount of data
transmitted,
such as transmitting only the difference between the latest local model
parameters and the last global model\footnote{\url{
    https://ai.googleblog.com/2017/04/federated-learning-collaborative.html
}.}, or leveraging sub-networks~\cite{li2021hermes}.
However,
the complexity these algorithms introduced on the client side may be undesirably
challenging.
